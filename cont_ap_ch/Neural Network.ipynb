{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dd39fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.stats import lognorm as lnorm\n",
    "from primitives import Parameters\n",
    "p = Parameters()\n",
    "import opt_einsum as oe\n",
    "from primitives import Preferences\n",
    "from probabilities import createPoissonTransitionMatrix,createBlockPoissonTransitionMatrix\n",
    "from search import JobSearchArray\n",
    "import matplotlib.pyplot as plt\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "def impose_decreasing(M):\n",
    "    nv = M.shape[1]\n",
    "    for v in reversed(range(nv-1)):\n",
    "        M[:,v,:] = np.maximum(M[:,v,:],M[:,v+1,:])\n",
    "    return M\n",
    "def impose_increasing(A0):\n",
    "    A = np.copy(A0)\n",
    "    nv = len(A)\n",
    "    for v in range(1,nv):\n",
    "        A[v] = np.maximum(A[v],A[v-1])\n",
    "    return A\n",
    "ax = np.newaxis\n",
    "class StateBoundsProcessor:\n",
    "    def __init__(self, lower_bounds, upper_bounds):\n",
    "        \"\"\"\n",
    "        Initialize with lower and upper bounds for each state dimension\n",
    "        \n",
    "        Args:\n",
    "            lower_bounds: List or tensor of lower bounds [x_1, x_2, ..., x_20]\n",
    "            upper_bounds: List or tensor of upper bounds [y_1, y_2, ..., y_20]\n",
    "        \"\"\"\n",
    "        self.lower_bounds = torch.tensor(lower_bounds, dtype=torch.float32)\n",
    "        self.upper_bounds = torch.tensor(upper_bounds, dtype=torch.float32)\n",
    "        self.range = self.upper_bounds - self.lower_bounds\n",
    "        \n",
    "    def normalize(self, states):\n",
    "        \"\"\"Scale states from [lower_bound, upper_bound] to [-1, 1]\"\"\"\n",
    "        return 2 * (states - self.lower_bounds) / self.range - 1\n",
    "        #Example: lower-upper is [0,1]. So normalize(0.5) = 2 * (0.5 - 0) /1 -1 = 0. Ok correct\n",
    "        #Another example. lower-upper is [0,30]. Sn normalize 15= 2 * 15 / 30 -1 = 0 Ok good.\n",
    "        # And normalize (20) = 40/30 - 1 = 1/3 yup\n",
    "        # Now denormalize(1/3) = 0.5 ( 1/3 +1 ) * 30 + 0 = 2/3*30 = 20\n",
    "        \n",
    "    def denormalize(self, normalized_states):\n",
    "        \"\"\"Convert normalized states back to original range\"\"\"\n",
    "        return 0.5 * (normalized_states + 1) * self.range + self.lower_bounds\n",
    "class ValueFunctionNN(nn.Module):\n",
    "    \"\"\"Neural network to approximate the value function\"\"\"\n",
    "    def __init__(self, state_dim, hidden_dims=[40, 30, 20, 10]):\n",
    "        super(ValueFunctionNN, self).__init__()\n",
    "        \n",
    "        # Build layers\n",
    "        layers = []\n",
    "        input_dim = state_dim\n",
    "        \n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            layers.append(nn.Softplus())  # SiLU activation function\n",
    "            # Consider adding layer normalization for stability\n",
    "            #layers.append(nn.LayerNorm(hidden_dim))\n",
    "            input_dim = hidden_dim\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(input_dim, 1)) #was input_dim instead of 16\n",
    "        \n",
    "        self.model = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "205077dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ContinuousContract import ContinuousContract\n",
    "cc=ContinuousContract(p)  \n",
    "cc.w_grid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6a4f7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0738998",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FOCOptimizer:\n",
    "    \"\"\"\n",
    "    Class to solve first-order conditions given a state and value function\n",
    "    This is a placeholder - you'll need to implement actual FOC logic\n",
    "    \"\"\"\n",
    "    def __init__(self, state_dim, action_dim, value_function_model, bounds_processor, parameters=None, js=None):\n",
    "        self.state_dim = state_dim\n",
    "        self.action_dim = action_dim\n",
    "        self.bounds_processor = bounds_processor  # Store bounds_processor\n",
    "\n",
    "        self.p = parameters\n",
    "        self.deriv_eps = 1e-4 # step size for derivative\n",
    "        # Model preferences initialized by the same parameter object.\n",
    "        self.pref = Preferences(input_param=self.p)\n",
    "\n",
    "        # Worker and Match Productivity Heterogeneity in the Model\n",
    "        self.Z_grid = self.construct_z_grid()   # Create match productivity grid\n",
    "\n",
    "        # Production Function in the Model\n",
    "        self.fun_prod = self.p.prod_a * np.power(self.Z_grid, self.p.prod_rho)\n",
    "        # Unemployment Benefits across Worker Productivities\n",
    "        self.unemp_bf = self.p.u_bf_m\n",
    "\n",
    "        # Transition matrices\n",
    "        self.Z_trans_mat = createPoissonTransitionMatrix(self.p.num_z, self.p.z_corr)\n",
    "\n",
    "        # Value Function Setup\n",
    "        self.J_grid   = -10 * np.ones((self.p.num_v)) #grid of job values, first productivity, then starting value, then tenure level\n",
    "        self.w_grid = np.linspace(self.unemp_bf, self.fun_prod.max(), self.p.num_v )\n",
    "        self.rho_grid=1/self.pref.utility_1d(self.w_grid)\n",
    "        # Normalize rho_grid to tensor for model input\n",
    "        self.rho_normalized = self.bounds_processor.normalize(torch.tensor(self.rho_grid, dtype=torch.float32)).unsqueeze(1)\n",
    "\n",
    "        \n",
    "        #Gotta fix the tightness+re functions somehow. Ultra simple J maybe?\n",
    "        self.v_grid=np.linspace(np.divide(self.pref.utility(self.unemp_bf),1-self.p.beta), np.divide(self.pref.utility(self.fun_prod.max()),1-self.p.beta), self.p.num_v ) #grid of submarkets the worker could theoretically search in. only used here for simplicity!!!\n",
    "        self.simple_J=np.divide(self.fun_prod[self.p.z_0-1,ax] -self.pref.inv_utility(self.v_grid[:]*(1-self.p.beta)),1-self.p.beta)\n",
    "        self.simple_Rho = self.simple_J + self.rho_grid * self.v_grid #We do indeed need to work with Rho here since we're taking W via its derivatives\n",
    "        #Apply the matching function: take the simple function and consider its different values across v.\n",
    "        self.prob_find_vx = self.p.alpha * np.power(1 - np.power(\n",
    "            np.divide(self.p.kappa, np.maximum(self.simple_J[ :], 1.0)), self.p.sigma), 1/self.p.sigma)\n",
    "        #Now get workers' probability to find a job while at some current value, as well as their return probabilities.\n",
    "        if js is None:\n",
    "            self.js = JobSearchArray() #Andrei: note that for us this array will have only one element\n",
    "            self.js.update(self.v_grid[:], self.prob_find_vx) #Andrei: two inputs: worker's value at the match quality of entrance (z_0-1), and the job-finding probability for the whole market\n",
    "        else:\n",
    "            self.js = js\n",
    "        #Note: I think??? js takes the values over the uniform grid only. so if I use NNs, gotta adapt it. But for now forget about updating it, keep it as is\n",
    "\n",
    "    def getWorkerDecisions(self, EW1, employed=True): #Andrei: Solves for the entire matrices of EW1 and EU\n",
    "        \"\"\"\n",
    "        :param EW1: Expected value of employment\n",
    "        :param EU:  Expected value of unemployment\n",
    "        :param employed: whether the worker is employed (in which case we multiply by efficiency)\n",
    "        :return: pe,re,qi search decision and associated return, as well as quit decision.\n",
    "        \"\"\"\n",
    "        pe, re = self.js.solve_search_choice(EW1) #Uses the job search array to solve for the search choice\n",
    "        assert (~np.isnan(pe)).all(), \"pe is not NaN\"\n",
    "        assert (pe <= 1).all(), \"pe is not less than 1\"\n",
    "        assert (pe >= -1e-10).all(), \"pe is not larger than 0\"\n",
    "        ve = self.js.ve(EW1)\n",
    "        if employed:\n",
    "            pe = pe * self.p.s_job\n",
    "            re = re * self.p.s_job\n",
    "        #print(\"Shape of pe:\", pe.shape)\n",
    "        # construct the continuation probability. #Andrei: probability the worker doesn't get fired and also doesn't leave\n",
    "        pc = (1 - pe)\n",
    "\n",
    "        return ve, re, pc #ve is vhat, the value the worker gets upon finding a job\n",
    "    def matching_function(self,J1): #Andrei: the formula of their matching function, applied to each particula job value J1\n",
    "        return self.p.alpha * np.power(1 - np.power(\n",
    "            np.divide(self.p.kappa, np.maximum(J1, self.p.kappa)), self.p.sigma),\n",
    "                                1 / self.p.sigma)\n",
    "    def construct_z_grid(self):\n",
    "        \"\"\"\n",
    "            Construct a grid for match productivity heterogeneity.\n",
    "        \"\"\"\n",
    "\n",
    "        exp_z = np.tile(np.linspace(0, 1, self.p.num_z + 2)[1:-1][:],\n",
    "                        (1))\n",
    "\n",
    "        return lnorm.ppf(q=exp_z, s=self.p.prod_var_z)    \n",
    "    def solve_foc(self, states, value_function_model):\n",
    "        \"\"\"\n",
    "        Solves first-order conditions to find optimal action and next state\n",
    "        \n",
    "        Args:\n",
    "            state: Current state tensor\n",
    "            value_function_model: Neural network model for value function\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with optimal action, next state, and immediate reward\n",
    "        \"\"\"\n",
    "        # This is a placeholder - replace with your actual FOC solver\n",
    "        # In a real implementation, you would:\n",
    "        # 1. Set up an optimization problem to find action that maximizes reward + discounted future value\n",
    "        # 2. Use value_function_model to evaluate future values\n",
    "        # 3. Return optimal action and resulting next state\n",
    "        # Compute gradient with gradients enabled\n",
    "        EW=self.EW\n",
    "        with torch.no_grad():\n",
    "            self.vf_output = value_function_model(self.rho_normalized).squeeze(1).numpy() #This EJpi from the CC FOC. I just precompute it for every point here\n",
    "        # Placeholder implementation (just random actions and states)\n",
    "        with torch.no_grad():\n",
    "            states_denorm = self.bounds_processor.denormalize(states).numpy()\n",
    "            # get worker decisions\n",
    "            _, _, pc = self.getWorkerDecisions(EW) #This EW1i is computed by taking the derivative of Rho, which is our core value function, wrt rho, which is the value-related state-variable\n",
    "            # get worker decisions at EW1i + epsilon\n",
    "            _, _, pc_d = self.getWorkerDecisions(EW + self.deriv_eps)\n",
    "            log_diff = np.zeros_like(self.rho_grid)\n",
    "            log_diff[:] = np.nan\n",
    "            log_diff[pc > 0] = np.log(pc_d[pc > 0]) - np.log(pc[pc > 0]) #This is log derivative of pc wrt the promised value\n",
    "            foc = self.rho_grid[:] - self.vf_output * log_diff / self.deriv_eps #So the FOC wrt promised value is: pay shadow cost lambda today (rho_grid), but more likely that the worker stays tomorrow\n",
    "            assert (np.isnan(foc) & (pc > 0)).sum() == 0, \"foc has NaN values where p>0\"\n",
    "\n",
    "                    #Andrei: so we look for the shadow cost that will satisfy the foc? Yes, look for u'(w'), with u'(w) given, so that the foc is satisfied\n",
    "                    # look for FOC below  rho_0\n",
    "\n",
    "            rho_star = np.interp(states_denorm,\n",
    "                                        impose_increasing(foc),\n",
    "                                        self.rho_grid)\n",
    "            rho_star_tensor = torch.tensor(rho_star, dtype=torch.float32)\n",
    "\n",
    "            action = rho_star_tensor\n",
    "            next_state = self.bounds_processor.normalize(rho_star_tensor)\n",
    "            reward = self.fun_prod[p.z_0-1] - np.interp(rho_star,self.rho_grid,self.w_grid) + states_denorm * self.pref.utility(np.interp(rho_star,self.rho_grid,self.w_grid))  # The entire Rho here. Big note though: this should be today's W, not EW\n",
    "            reward = torch.tensor(reward, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "        return {\n",
    "            \"action\": action,\n",
    "            \"next_state\": next_state,\n",
    "            \"reward\": reward\n",
    "        }\n",
    "    def get_batch_gradients(self,states, value_function_model):\n",
    "        states = states.detach().clone().requires_grad_(True)\n",
    "        values = value_function_model(states)\n",
    "    \n",
    "        # Sum values to get scalar for backward pass\n",
    "        values.sum().backward(retain_graph=True)\n",
    "    \n",
    "        gradients = states.grad.clone()\n",
    "        # Clear gradients for next computation\n",
    "        states.grad.zero_()\n",
    "        gradients = gradients / (0.5 * self.bounds_processor.range) #Normalize the gradient back to the original (not [-1,1]) state space\n",
    "\n",
    "        return gradients    \n",
    "    def get_value_function_gradient(self,state, value_function_model):\n",
    "        # Ensure state requires gradients\n",
    "        #if not state.requires_grad:\n",
    "        state = state.detach().clone().requires_grad_(True)\n",
    "    \n",
    "        # Forward pass\n",
    "        value = value_function_model(state)\n",
    "    \n",
    "        # Compute gradient of value with respect to state\n",
    "        #value.retain_grad()\n",
    "        value.sum().backward(retain_graph=True)\n",
    "\n",
    "        # Extract gradient\n",
    "        gradient = state.grad.clone()\n",
    "    \n",
    "        # Clear gradients for next computation\n",
    "        state.grad.zero_()\n",
    "        gradient = gradient / (0.5 * self.bounds_processor.range) #Normalize the gradient back to the original (not [-1,1]) state space\n",
    "        return gradient\n",
    "    #This can definitely be vectorized. So far each trajectory is done completely separately, even though the operations at each step are the same, no?\n",
    "    def simulate_trajectory(self,state, value_function_model, foc_optimizer, steps=5):\n",
    "        \"\"\"\n",
    "        Simulate a trajectory starting from a state and using the current value function\n",
    "    \n",
    "        Args:\n",
    "            state: Starting state tensor\n",
    "            value_function_model: Current value function model\n",
    "            foc_optimizer: Optimizer to solve FOCs\n",
    "            steps: Number of steps to simulate\n",
    "        \n",
    "        Returns:\n",
    "            Total discounted reward and final state value\n",
    "        \"\"\"\n",
    "        total_reward = 0\n",
    "        discount = 1.0\n",
    "    \n",
    "        current_state = state.clone()\n",
    "        with torch.enable_grad():\n",
    "            EW_tensor = self.get_batch_gradients(self.rho_normalized, value_function_model)[:,0] #This isn't even correct! I should be taking this at all the rho's!\n",
    "        self.EW = EW_tensor.detach().numpy()  # Convert to NumPy for further processing\n",
    "        for _ in range(steps):\n",
    "            \n",
    "            # Solve FOC to get optimal action and next state\n",
    "            result = foc_optimizer.solve_foc(current_state, value_function_model)\n",
    "            #Probability that the worker stays\n",
    "            EW_star = self.get_batch_gradients(result[\"next_state\"].unsqueeze(1).requires_grad_(True), value_function_model)[:,0]\n",
    "            ve_star, __, pc_star = self.getWorkerDecisions(EW_star.numpy())\n",
    "            ve_star = torch.from_numpy(ve_star)\n",
    "            pc_star = torch.from_numpy(pc_star)            \n",
    "            # Accumulate discounted reward\n",
    "            if _<range(steps)[-1]:\n",
    "                total_reward += discount * result[\"reward\"] + self.p.beta * self.bounds_processor.denormalize(current_state) * ( 1 - pc_star) * ve_star  #This should be: reward + rho*beta*ve_star*pe_star (so the value worker gets from leaving) + discount*next_reward\n",
    "            else:\n",
    "                total_reward += discount * result[\"reward\"] #for the last period we don't enymore do ve_star as that's included... right? confirm later\n",
    "            # Update state and discount factor\n",
    "            current_state = result[\"next_state\"]\n",
    "            discount *= self.p.beta * pc_star\n",
    "    \n",
    "        # Add final state value\n",
    "        with torch.no_grad():\n",
    "            final_value = value_function_model(current_state.unsqueeze(1).requires_grad_(True))\n",
    "    \n",
    "        total_value = total_reward + discount * final_value\n",
    "    \n",
    "        return total_value, current_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d534e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_value_function(\n",
    "    state_dim,\n",
    "    lower_bounds,\n",
    "    upper_bounds,\n",
    "    action_dim=5,\n",
    "    hidden_dims=[40, 30, 20, 10],\n",
    "    num_iterations=20, \n",
    "    starting_points_per_iter=100,\n",
    "    simulation_steps=5,\n",
    "    learning_rate=0.001,\n",
    "    parameters=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Main training loop for value function approximation\n",
    "    \n",
    "    Args:\n",
    "        state_dim: Dimension of state space\n",
    "        action_dim: Dimension of action space\n",
    "        hidden_dims: List of hidden layer dimensions\n",
    "        num_iterations: Number of training iterations\n",
    "        starting_points_per_iter: Number of starting points per iteration\n",
    "        simulation_steps: Steps to simulate for each starting point\n",
    "        learning_rate: Learning rate for neural network optimizer\n",
    "        discount_factor: Discount factor for future rewards\n",
    "    \n",
    "    Returns:\n",
    "        Trained value function model\n",
    "    \"\"\"\n",
    "    bounds_processor = StateBoundsProcessor(lower_bounds,upper_bounds)\n",
    "    # Initialize value function neural network\n",
    "    value_function_model = ValueFunctionNN(state_dim, hidden_dims)\n",
    "    from ContinuousContract import ContinuousContract\n",
    "    cc=ContinuousContract(p)\n",
    "    # Initialize FOC optimizer\n",
    "    foc_optimizer = FOCOptimizer(state_dim, action_dim, value_function_model, bounds_processor, parameters, cc.js)\n",
    "    \n",
    "    # Initialize neural network optimizer\n",
    "    optimizer = optim.Adam(value_function_model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    #Step 0: basic guess    \n",
    "    cc_J,cc_W,_,_ = cc.J()\n",
    "    target_values = torch.tensor(cc_J[p.z_0-1,:] + cc.rho_grid * cc_W[p.z_0-1,:], dtype=torch.float32)\n",
    "    states=bounds_processor.normalize(torch.tensor(foc_optimizer.rho_grid, dtype=torch.float32)).unsqueeze(1).requires_grad_(True) #This should be renormalized... right?\n",
    "    #print(np.max(np.abs(cc.rho_grid-foc_optimizer.rho_grid)))\n",
    "    #target_values=torch.tensor(foc_optimizer.simple_Rho, dtype=torch.float32)\n",
    "    for _ in (range(50)):\n",
    "        optimizer.zero_grad()\n",
    "        predicted_values = value_function_model(states)[:,0]\n",
    "        loss = nn.MSELoss()(predicted_values, target_values)\n",
    "        loss.backward() #\n",
    "        optimizer.step()\n",
    "\n",
    "    # Training loop\n",
    "    for iteration in tqdm(range(num_iterations)):\n",
    "        # Generate uniform random starting states\n",
    "        states_denormal = torch.rand(starting_points_per_iter, state_dim,dtype=torch.float32) * bounds_processor.range + torch.tensor(lower_bounds,dtype=torch.float32) #Turning lower_bounds into torch every time is wasteful\n",
    "        states = bounds_processor.normalize(states_denormal).requires_grad_(True)\n",
    "        #print(\"States shape\", states.shape)\n",
    "        # Calculate target values through simulation\n",
    "        target_values = []\n",
    "\n",
    "        # Simulate trajectory and get total discounted reward\n",
    "        target_values, _ = foc_optimizer.simulate_trajectory(\n",
    "            states[:,0], value_function_model, foc_optimizer, simulation_steps)\n",
    "        #target_values.append(total_values)\n",
    "        \n",
    "        #target_values = torch.tensor(target_values, dtype=torch.float32)\n",
    "        \n",
    "        # Update neural network based on simulated values\n",
    "        optimizer.zero_grad()\n",
    "        predicted_values = value_function_model(states)\n",
    "        loss = nn.MSELoss()(predicted_values, target_values)\n",
    "        loss.backward() #\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print progress\n",
    "        if (iteration + 1) % 5 == 0 or iteration == 0:\n",
    "            print(f\"Iteration {iteration + 1}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return value_function_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f041660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_value_function(model, p, lower_bounds,upper_bounds):\n",
    "    \"\"\"\n",
    "    Evaluate the trained value function on test points\n",
    "    \n",
    "    Args:\n",
    "        model: Trained value function model\n",
    "        num_test_points: Number of test points\n",
    "        state_dim: Dimension of state space\n",
    "    \"\"\"\n",
    "\n",
    "    bounds_processor = StateBoundsProcessor(lower_bounds,upper_bounds)\n",
    "    # Generate random test states\n",
    "    #test_states = torch.randn(num_test_points, state_dim)\n",
    "    from ContinuousContract import ContinuousContract\n",
    "    cc=ContinuousContract(p)    \n",
    "    cc_J,cc_W,_,_ = cc.J()\n",
    "    cc_Rho = cc_J[p.z_0-1,:] + cc.rho_grid * cc_W[p.z_0-1,:]\n",
    "    test_states = bounds_processor.normalize(torch.tensor(cc.rho_grid, dtype=torch.float32)).unsqueeze(1)\n",
    "    # Evaluate model\n",
    "    with torch.no_grad():\n",
    "        values = model(test_states)\n",
    "    \n",
    "    # Print results\n",
    "    #print(\"\\nValue function evaluation on test states:\")\n",
    "    #for i in range(min(5, num_test_points)):\n",
    "    #    print(f\"State {i+1}: Value = {values[i].item():.4f}\")\n",
    "    #Plot results\n",
    "    plt.plot(cc.rho_grid, cc_Rho, label = \"VFI\")\n",
    "    plt.plot(cc.rho_grid, values, label = \"NN\")    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0769e0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training value function...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/690 [00:00<?, ?it/s]c:\\Programs\\Python 3.11\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:610: UserWarning: Using a target size (torch.Size([200, 200])) that is different to the input size (torch.Size([200, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "  2%|▏         | 11/690 [00:00<00:06, 107.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: 76970.539062\n",
      "Iteration 5, Loss: 72109.554688\n",
      "Iteration 10, Loss: 67536.468750\n",
      "Iteration 15, Loss: 64638.335938\n",
      "Iteration 20, Loss: 61628.710938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 34/690 [00:00<00:06, 100.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 25, Loss: 56396.363281\n",
      "Iteration 30, Loss: 55585.351562\n",
      "Iteration 35, Loss: 55838.453125\n",
      "Iteration 40, Loss: 58460.312500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 56/690 [00:00<00:06, 96.84it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 45, Loss: 57278.343750\n",
      "Iteration 50, Loss: 52494.667969\n",
      "Iteration 55, Loss: 45388.777344\n",
      "Iteration 60, Loss: 49214.507812\n",
      "Iteration 65, Loss: 41844.488281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 88/690 [00:00<00:06, 99.15it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 70, Loss: 45584.929688\n",
      "Iteration 75, Loss: 41550.546875\n",
      "Iteration 80, Loss: 36385.421875\n",
      "Iteration 85, Loss: 35478.015625\n",
      "Iteration 90, Loss: 34189.691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 108/690 [00:01<00:05, 98.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 95, Loss: 28260.531250\n",
      "Iteration 100, Loss: 31917.298828\n",
      "Iteration 105, Loss: 24590.832031\n",
      "Iteration 110, Loss: 25988.365234\n",
      "Iteration 115, Loss: 27807.263672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 130/690 [00:01<00:05, 98.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 120, Loss: 21942.261719\n",
      "Iteration 125, Loss: 24078.388672\n",
      "Iteration 130, Loss: 22344.876953\n",
      "Iteration 135, Loss: 21451.484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 150/690 [00:01<00:05, 97.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 140, Loss: 19812.988281\n",
      "Iteration 145, Loss: 18037.863281\n",
      "Iteration 150, Loss: 20815.517578\n",
      "Iteration 155, Loss: 18661.146484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 171/690 [00:01<00:05, 97.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 160, Loss: 18309.794922\n",
      "Iteration 165, Loss: 18144.355469\n",
      "Iteration 170, Loss: 18250.525391\n",
      "Iteration 175, Loss: 18419.386719\n",
      "Iteration 180, Loss: 20989.898438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 196/690 [00:01<00:04, 108.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 185, Loss: 17865.916016\n",
      "Iteration 190, Loss: 19650.806641\n",
      "Iteration 195, Loss: 18474.757812\n",
      "Iteration 200, Loss: 20442.035156\n",
      "Iteration 205, Loss: 19350.880859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 221/690 [00:02<00:04, 103.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 210, Loss: 19829.423828\n",
      "Iteration 215, Loss: 21531.296875\n",
      "Iteration 220, Loss: 20116.769531\n",
      "Iteration 225, Loss: 20582.837891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 244/690 [00:02<00:04, 106.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 230, Loss: 18199.599609\n",
      "Iteration 235, Loss: 18620.585938\n",
      "Iteration 240, Loss: 19295.138672\n",
      "Iteration 245, Loss: 19749.414062\n",
      "Iteration 250, Loss: 18573.439453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 267/690 [00:02<00:03, 108.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 255, Loss: 19274.099609\n",
      "Iteration 260, Loss: 19616.333984\n",
      "Iteration 265, Loss: 17480.783203\n",
      "Iteration 270, Loss: 20019.242188\n",
      "Iteration 275, Loss: 19612.861328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 291/690 [00:02<00:03, 107.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 280, Loss: 18404.085938\n",
      "Iteration 285, Loss: 20037.208984\n",
      "Iteration 290, Loss: 18876.380859\n",
      "Iteration 295, Loss: 19109.404297\n",
      "Iteration 300, Loss: 18947.312500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 315/690 [00:03<00:03, 111.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 305, Loss: 17784.736328\n",
      "Iteration 310, Loss: 19768.351562\n",
      "Iteration 315, Loss: 18890.863281\n",
      "Iteration 320, Loss: 20077.398438\n",
      "Iteration 325, Loss: 20057.685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 351/690 [00:03<00:03, 107.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 330, Loss: 18680.552734\n",
      "Iteration 335, Loss: 19426.962891\n",
      "Iteration 340, Loss: 16701.929688\n",
      "Iteration 345, Loss: 18318.943359\n",
      "Iteration 350, Loss: 20035.363281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 374/690 [00:03<00:02, 110.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 355, Loss: 21422.601562\n",
      "Iteration 360, Loss: 19583.431641\n",
      "Iteration 365, Loss: 20106.630859\n",
      "Iteration 370, Loss: 18396.732422\n",
      "Iteration 375, Loss: 19521.865234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 398/690 [00:03<00:02, 108.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 380, Loss: 17914.000000\n",
      "Iteration 385, Loss: 20502.482422\n",
      "Iteration 390, Loss: 17482.863281\n",
      "Iteration 395, Loss: 19816.234375\n",
      "Iteration 400, Loss: 17958.048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 422/690 [00:04<00:02, 112.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 405, Loss: 20776.250000\n",
      "Iteration 410, Loss: 19926.167969\n",
      "Iteration 415, Loss: 17955.082031\n",
      "Iteration 420, Loss: 16864.923828\n",
      "Iteration 425, Loss: 19793.650391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 446/690 [00:04<00:02, 105.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 430, Loss: 17505.017578\n",
      "Iteration 435, Loss: 20612.623047\n",
      "Iteration 440, Loss: 20992.761719\n",
      "Iteration 445, Loss: 21013.830078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 468/690 [00:04<00:02, 105.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 450, Loss: 16816.406250\n",
      "Iteration 455, Loss: 20139.148438\n",
      "Iteration 460, Loss: 18703.769531\n",
      "Iteration 465, Loss: 20469.003906\n",
      "Iteration 470, Loss: 17950.414062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 492/690 [00:04<00:01, 109.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 475, Loss: 18867.992188\n",
      "Iteration 480, Loss: 18867.576172\n",
      "Iteration 485, Loss: 18572.474609\n",
      "Iteration 490, Loss: 18818.291016\n",
      "Iteration 495, Loss: 18402.703125\n",
      "Iteration 500, Loss: 20514.597656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 517/690 [00:04<00:01, 110.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 505, Loss: 20486.615234\n",
      "Iteration 510, Loss: 16990.066406\n",
      "Iteration 515, Loss: 19880.011719\n",
      "Iteration 520, Loss: 20501.070312\n",
      "Iteration 525, Loss: 17809.271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 543/690 [00:05<00:01, 116.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 530, Loss: 19705.542969\n",
      "Iteration 535, Loss: 19365.458984\n",
      "Iteration 540, Loss: 18211.828125\n",
      "Iteration 545, Loss: 19124.736328\n",
      "Iteration 550, Loss: 19165.535156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 568/690 [00:05<00:01, 117.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 555, Loss: 19721.863281\n",
      "Iteration 560, Loss: 20375.552734\n",
      "Iteration 565, Loss: 19009.031250\n",
      "Iteration 570, Loss: 19404.695312\n",
      "Iteration 575, Loss: 19783.046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 592/690 [00:05<00:00, 111.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 580, Loss: 22191.101562\n",
      "Iteration 585, Loss: 19016.853516\n",
      "Iteration 590, Loss: 19007.849609\n",
      "Iteration 595, Loss: 18011.162109\n",
      "Iteration 600, Loss: 17450.410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 628/690 [00:05<00:00, 112.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 605, Loss: 18592.802734\n",
      "Iteration 610, Loss: 18112.125000\n",
      "Iteration 615, Loss: 19573.339844\n",
      "Iteration 620, Loss: 18260.947266\n",
      "Iteration 625, Loss: 18357.128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 640/690 [00:05<00:00, 111.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 630, Loss: 18886.308594\n",
      "Iteration 635, Loss: 21203.359375\n",
      "Iteration 640, Loss: 19469.181641\n",
      "Iteration 645, Loss: 20190.730469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 664/690 [00:06<00:00, 107.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 650, Loss: 20686.773438\n",
      "Iteration 655, Loss: 20191.250000\n",
      "Iteration 660, Loss: 18671.578125\n",
      "Iteration 665, Loss: 18344.996094\n",
      "Iteration 670, Loss: 18832.445312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 690/690 [00:06<00:00, 107.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 675, Loss: 18679.669922\n",
      "Iteration 680, Loss: 19503.365234\n",
      "Iteration 685, Loss: 19993.189453\n",
      "Iteration 690, Loss: 20521.265625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to trained_value_function.pt\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Define parameters\n",
    "    STATE_DIM = 1  # Just one, continuous state, the promised value. Next step will be adding (discrete) y\n",
    "    ACTION_DIM = 1  # Adjust based on your problem\n",
    "    HIDDEN_DIMS = [64,64]  # Decreasing width architecture\n",
    "    pref = Preferences(input_param=p)\n",
    "    \n",
    "    LOWER_BOUNDS = [1/pref.utility_1d(p.u_bf_m)]\n",
    "    UPPER_BOUNDS = [1/pref.utility_1d(10)] #Ideally this should come from fun_prod.max\n",
    "    # Train value function\n",
    "    print(\"Training value function...\")\n",
    "    trained_model = train_value_function(\n",
    "        state_dim=STATE_DIM,\n",
    "        lower_bounds=LOWER_BOUNDS,\n",
    "        upper_bounds=UPPER_BOUNDS,\n",
    "        action_dim=ACTION_DIM,\n",
    "        hidden_dims=HIDDEN_DIMS,\n",
    "        num_iterations=690,\n",
    "        starting_points_per_iter=200,\n",
    "        simulation_steps=5,\n",
    "        learning_rate=0.003,\n",
    "        parameters=p\n",
    "    )\n",
    "    \n",
    "    # Evaluate trained model\n",
    "    evaluate_value_function(trained_model, p, LOWER_BOUNDS, UPPER_BOUNDS)\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(trained_model.state_dict(), \"trained_value_function.pt\")\n",
    "    print(\"Model saved to trained_value_function.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "24a35ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3215.1104], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_model(torch.tensor([-40.0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
